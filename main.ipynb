{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdcjvXs4d60N"
      },
      "source": [
        "install library if not"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b8DVHFCz62Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8509f95-7c89-45ff-ea9a-7990d75e99ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.40.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.40.0 watchdog-5.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiona"
      ],
      "metadata": {
        "id": "qk2wooA-veNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6bff7c49-1480-44df-8117-f15613dcf552"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona) (2024.8.30)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (8.1.7)\n",
            "Collecting click-plugins>=1.0 (from fiona)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting cligj>=0.5 (from fiona)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading fiona-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Installing collected packages: cligj, click-plugins, fiona\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mapclassify matplotlib"
      ],
      "metadata": {
        "id": "eshJtIKU96qY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81510b57-9341-43f8-8458-c81384523b41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mapclassify\n",
            "  Downloading mapclassify-2.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (1.26.4)\n",
            "Requirement already satisfied: pandas!=1.5.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->mapclassify) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->mapclassify) (3.5.0)\n",
            "Downloading mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mapclassify\n",
            "Successfully installed mapclassify-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary library"
      ],
      "metadata": {
        "id": "xiyfFpWruwd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xzJjq29EwLr3"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import mapclassify\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "import fiona\n",
        "import pyproj\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry import box\n",
        "from collections import OrderedDict\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hardcoded constant value."
      ],
      "metadata": {
        "id": "wpkUqK8LH9Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data dictionary\n",
        "data = {\n",
        "    'SN': range(1, 26),\n",
        "    'scientific_name': ['Abies spp', 'Acacia catechu', 'Adina cardifolia', 'Albizia spp', 'Alnus nepalensis',\n",
        "                       'Anogeissus latifolia', 'Bombax ceiba', 'Cedrela toona', 'Dalbergia sissoo',\n",
        "                       'Eugenia Jambolana', 'Hymenodictyon excelsum', 'Lagerstroemia parviflora',\n",
        "                       'Michelia champaca', 'Pinus roxburghii', 'Pinus wallichiana', 'Quercus spp',\n",
        "                       'Schima wallichii', 'Shorea robusta', 'Terminalia alata', 'Trewia nudiflora',\n",
        "                       'Tsuga spp', 'Terai spp', 'Hill spp', 'Coniferious', 'Broadleaved'],\n",
        "    'a': [-2.4453, -2.3256, -2.5626, -2.4284, -2.7761, -2.272, -2.3856, -2.1832, -2.1959, -2.5693,\n",
        "          -2.585, -2.3411, -2.0152, -2.977, -2.8195, -2.36, -2.7385, -2.4554, -2.4616, -2.4585,\n",
        "          -2.5293, -2.3993, -2.3204, np.nan, np.nan],\n",
        "    'b': [1.722, 1.6476, 1.8598, 1.7609, 1.9006, 1.7499, 1.7414, 1.8679, 1.6567, 1.8816,\n",
        "          1.9437, 1.7246, 1.8555, 1.9235, 1.725, 1.968, 1.8155, 1.9026, 1.8497, 1.8043,\n",
        "          1.7815, 1.7836, 1.8507, np.nan, np.nan],\n",
        "    'c': [1.0757, 1.0552, 0.8783, 0.9662, 0.9428, 0.9174, 1.0063, 0.7569, 0.9899, 0.8498,\n",
        "          0.7902, 0.9702, 0.763, 1.0019, 1.1623, 0.7496, 1.0072, 0.8352, 0.88, 0.922,\n",
        "          1.0369, 0.9546, 0.8223, np.nan, np.nan],\n",
        "    'a1': [5.4433, 5.4401, 5.4681, 4.4031, 6.019, 4.9502, 4.5554, 4.9705, 4.358, 5.1749,\n",
        "           5.5572, 5.3349, 3.3499, 6.2696, 5.7216, 4.8511, 7.4617, 5.2026, 4.5968, 5.3475,\n",
        "           5.2774, 4.8991, 5.5323, np.nan, np.nan],\n",
        "    'b1': [-2.6902, -2.491, -2.491, -2.2094, -2.7271, -2.3353, -2.3009, -2.3436, -2.1559, -2.3636,\n",
        "           -2.496, -2.4428, -2.0161, -2.8252, -2.6788, -2.4494, -3.0676, -2.4788, -2.2305, -2.4774,\n",
        "           -2.6483, -2.3406, -2.4815, np.nan, np.nan],\n",
        "    's': [0.436, 0.443, 0.443, 0.443, 0.803, 0.443, 0.443, 0.443, 0.684, 0.443,\n",
        "          0.443, 0.443, 0.443, 0.189, 0.683, 0.747, 0.52, 0.055, 0.443, 0.443,\n",
        "          0.443, 0.443, 0.443, 0.436, 0.443],\n",
        "    'm': [0.372, 0.511, 0.511, 0.511, 1.226, 0.511, 0.511, 0.511, 0.684, 0.511,\n",
        "          0.511, 0.511, 0.511, 0.256, 0.488, 0.96, 0.186, 0.341, 0.511, 0.511,\n",
        "          0.511, 0.511, 0.511, 0.372, 0.511],\n",
        "    'bg': [0.355, 0.71, 0.71, 0.71, 1.51, 0.71, 0.71, 0.71, 0.684, 0.71,\n",
        "           0.71, 0.71, 0.71, 0.3, 0.41, 1.06, 0.168, 0.357, 0.71, 0.71,\n",
        "           0.71, 0.71, 0.71, 0.355, 0.71],\n",
        "    'Local_Name': ['Thingre Salla', 'Khayar', 'Karma', 'Siris', 'Uttis', 'Banjhi', 'Simal', 'Tooni',\n",
        "                   'Sissoo', 'Jamun', 'Bhudkul', 'Botdhayero', 'Chanp', 'Khote Salla', 'Gobre Salla',\n",
        "                   'Kharsu', 'Chilaune', 'Sal', 'Saj', 'Gamhari', 'Dhupi Salla', 'Terai Spp',\n",
        "                   'Hill spp', '', '']\n",
        "}"
      ],
      "metadata": {
        "id": "pmYeLXZGPOxv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "wrap constant data in a variable"
      ],
      "metadata": {
        "id": "h_GZguKZu_33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sppVal = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "rgpB_ZW2RkAY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiS2hN-FfY8O"
      },
      "source": [
        "#Upload Stem mapping csv file using streamlit library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Replace the file upload code\n",
        "uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    # ... (rest of your code that uses df)\n",
        "else:\n",
        "    st.write(\"Please upload tree location or stem mapping CSV file.\")'''"
      ],
      "metadata": {
        "id": "mTmFFsjQZ1yS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "608fd2b0-3e84-457a-8202-61e96300f5a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-08 12:04:52.007 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.009 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.011 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.022 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.238 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-11-08 12:04:52.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.244 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-08 12:04:52.251 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing purpose to upload file I am using geopandas. when using streamlit comment this code."
      ],
      "metadata": {
        "id": "szLBx-89jLAk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MyjUZY7ofoiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2fb5b9a7-9f86-4ceb-aa87-93fbadd89f30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6eb8f86-bad7-4236-8196-63fce7477657\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e6eb8f86-bad7-4236-8196-63fce7477657\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TreeLoc.csv to TreeLoc.csv\n"
          ]
        }
      ],
      "source": [
        "stemmapping = files.upload()\n",
        "df = pd.read_csv('TreeLoc.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4hJy-yWyrrc"
      },
      "source": [
        "Read sppVal.csv table inorder to join dataframe with its species value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecEEmW73QjHf"
      },
      "source": [
        "# Join the GeoDataFrames based on the 'species' column\n",
        "merged_gdf = df_with_remarks.merge(sppVal, left_on='species', right_on='Scientific Name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1TrXTc77QET2"
      },
      "outputs": [],
      "source": [
        "joined_df = df.merge(sppVal, left_on='species', right_on='scientific_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-N4jpQWhXF9"
      },
      "source": [
        "copy the joined_df as 'result_df'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zoSWMPHIcncv"
      },
      "outputs": [],
      "source": [
        "result_df = joined_df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6idGzbqBmWTL"
      },
      "source": [
        "## Function to perform calculations and add new columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irpZ1UgYmPCn"
      },
      "outputs": [],
      "source": [
        "def add_calculated_columns(df):\n",
        "    df['stem_volume'] = np.exp(df['a'] + df['b'] * np.log(df['dia_cm']) + df['c'] * np.log(df['height_m'])) / 1000\n",
        "    df['branch_ratio'] = df['dia_cm'].apply(lambda x: 0.1 if x < 10 else 0.2)\n",
        "    df['branch_volume'] = df['stem_volume'] * df['branch_ratio']\n",
        "    df['tree_volume'] = df['stem_volume'] + df['branch_volume']\n",
        "    df['cm10diaratio'] = np.exp(df['a1'] + df['b1'] * np.log(df['dia_cm']))\n",
        "    df['cm10topvolume'] = df['stem_volume'] * df['cm10diaratio']\n",
        "    df['gross_volume'] = df['stem_volume'] - df['cm10topvolume']\n",
        "    df['net_volume'] = df.apply(lambda row: row['gross_volume'] * 0.9 if row['class'] == 'A' else row['gross_volume'] * 0.8, axis=1)\n",
        "    df['net_volum_cft'] = df['net_volume'] * 35.3147\n",
        "    df['firewood_m3'] = df['tree_volume'] - df['net_volume']\n",
        "    df['firewood_chatta'] = df['firewood_m3'] * 0.105944\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IINYZ_RUNQN"
      },
      "source": [
        "Apply the function to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlISXKdMyJkG"
      },
      "outputs": [],
      "source": [
        "result_df = add_calculated_columns(df=result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8wWmOy62zNS"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['SN', 'scientific_name', 'a', 'b', 'c', 'a1', 'b1', 's', 'm', 'bg']\n",
        "result_df = result_df.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the result using streamlit instead of other library."
      ],
      "metadata": {
        "id": "2rYX2EbXvoCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv('result_df.csv', index=False)\n",
        "files.download('result_df.csv')"
      ],
      "metadata": {
        "id": "c2qT16AnpyIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download result using streamlit library."
      ],
      "metadata": {
        "id": "a74WIOdjv0eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (your existing code) ...\n",
        "\n",
        "# Download button\n",
        "@st.cache_data\n",
        "def convert_df(df):\n",
        "    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "    return df.to_csv(index=False).encode('utf-8')\n",
        "\n",
        "csv = convert_df(result_df)\n",
        "\n",
        "st.download_button(\n",
        "    label=\"Download data as CSV\",\n",
        "    data=csv,\n",
        "    file_name='result_df.csv',\n",
        "    mime='text/csv',\n",
        ")"
      ],
      "metadata": {
        "id": "fJsf4RePvsjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#convert pandas dataframe to geopandas dataframe"
      ],
      "metadata": {
        "id": "Xiw1xs5Z-NUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df['geometry'] = result_df.apply(lambda row: Point(row['LONGITUDE'], row['LATITUDE']), axis=1)"
      ],
      "metadata": {
        "id": "Lc3qePPe_8yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_gdf = gpd.GeoDataFrame(result_df, geometry='geometry', crs='epsg:4326')"
      ],
      "metadata": {
        "id": "Rs-qkVQhAMZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_gdf.explore()"
      ],
      "metadata": {
        "id": "bl__mG5jFn2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "'''# @title Spatial Distribution of Tree Species\n",
        "# Assuming your data is in a pandas DataFrame called 'df'\n",
        "plt.figure(figsize=(10, 8))\n",
        "for species in df['species'].unique():\n",
        "    subset = df[df['species'] == species]\n",
        "    plt.scatter(subset['LONGITUDE'], subset['LATITUDE'], label=species, alpha=0.6, s=2)  # Adjust 's' for marker size\n",
        "\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Spatial Distribution of Tree Species')\n",
        "_ = plt.legend(loc='upper left', bbox_to_anchor=(1, 1), title='Species')  # Place legend outside the plot'''"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "wmfNCfPXA0Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Bounding box withing tree map extent and will be used to generate grid of twenty meter"
      ],
      "metadata": {
        "id": "9y94QwGOy6kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total bounds (xmin, ymin, xmax, ymax)\n",
        "xmin, ymin, xmax, ymax = result_gdf.total_bounds\n",
        "# Create a Polygon using the bounds\n",
        "bounding_polygon = box(xmin, ymin, xmax, ymax)\n",
        "# Optionally, create a GeoDataFrame with the bounding polygon\n",
        "bounding_gdf = gpd.GeoDataFrame(geometry=[bounding_polygon], crs=result_gdf.crs)"
      ],
      "metadata": {
        "id": "8XxVHVJvy54P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#in this code user need to enter tree spacinge float value using streamlit library. for convinience purpose here geopandas library is used."
      ],
      "metadata": {
        "id": "sTfDrsU21xWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'bounding_gdf' is already defined and is a GeoDataFrame.\n",
        "# Also assuming you have a way to get user input from a textbox (e.g., using a GUI library).\n",
        "\n",
        "# Replace this with your actual method of getting user input.\n",
        "user_input_spacing = input(\"Enter grid spacing in meters (default is 20m): \")\n",
        "\n",
        "try:\n",
        "    grid_spacing = float(user_input_spacing)  # Try to convert input to float\n",
        "except ValueError:\n",
        "    grid_spacing = 20  # Use default if input is invalid\n",
        "\n",
        "# Now use grid_spacing to create your grid using bounding_gdf\n",
        "# Example (replace with actual code):\n",
        "\n",
        "# ... your code to create the grid using grid_spacing and bounding_gdf ..."
      ],
      "metadata": {
        "id": "4e-I8h2t_qex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create grid"
      ],
      "metadata": {
        "id": "4U6vSe0sBz5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'bounding_gdf' is your GeoDataFrame in 'EPSG:4326'\n",
        "\n",
        "# Define the grid spacing in meters (20 meters in this case)\n",
        "spacing_meters = 100\n",
        "\n",
        "# Get the bounds of the bounding geometry\n",
        "xmin, ymin, xmax, ymax = bounding_gdf.total_bounds\n",
        "\n",
        "# Create a pyproj transformer to convert meters to degrees\n",
        "transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", bounding_gdf.crs, always_xy=True)\n",
        "\n",
        "# Calculate spacing in degrees based on the center of the bounding box\n",
        "center_lat = (ymin + ymax) / 2\n",
        "spacing_degrees = spacing_meters / (111320 * np.cos(np.deg2rad(center_lat)))  # Approximate conversion\n",
        "\n",
        "# Create a list of x and y coordinates for the grid points\n",
        "x_coords = np.arange(xmin, xmax, spacing_degrees)\n",
        "y_coords = np.arange(ymin, ymax, spacing_degrees)\n",
        "\n",
        "# Create a list of polygons representing the grid cells\n",
        "polygons = []\n",
        "for x in x_coords:\n",
        "    for y in y_coords:\n",
        "        polygons.append(Polygon([(x, y), (x + spacing_degrees, y),\n",
        "                                 (x + spacing_degrees, y + spacing_degrees), (x, y + spacing_degrees)]))\n",
        "\n",
        "# Create a GeoDataFrame from the polygons\n",
        "grid_gdf = gpd.GeoDataFrame({'geometry': polygons}, crs='EPSG:4326')\n",
        "\n",
        "# (Optional) Clip the grid to the bounding geometry\n",
        "grid_gdf = gpd.clip(grid_gdf, bounding_gdf)"
      ],
      "metadata": {
        "id": "HjTEP1ECByjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_gdf.explore()"
      ],
      "metadata": {
        "id": "0K-fiohRDdKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ... (your existing code to create grid_gdf and result_gdf) ...\n",
        "\n",
        "# Perform a spatial join to find intersecting polygons, but keep only the grid cell index\n",
        "intersected_grid_indices = gpd.sjoin(grid_gdf, result_gdf, how='inner', predicate='intersects').index.unique()\n",
        "\n",
        "# Select the unique grid cells from grid_gdf based on the indices\n",
        "selected_polygons_gdf = grid_gdf[grid_gdf.index.isin(intersected_grid_indices)]\n",
        "\n",
        "# (Optional) Reset index\n",
        "selected_polygons_gdf = selected_polygons_gdf.reset_index(drop=True)\n",
        "\n",
        "# ... (further processing) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1Y1YsJiPD07w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_polygons_gdf.explore()"
      ],
      "metadata": {
        "id": "YozWtDcUZXLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create Bounding box"
      ],
      "metadata": {
        "id": "eHCHEEtfKJeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating grid and centroid of the grid"
      ],
      "metadata": {
        "id": "Xj-F3d1AFJyH"
      }
    },
    {
      "source": [
        "# Get the bounds of your bounding GeoDataFrame\n",
        "xmin, ymin, xmax, ymax = bounding_gdf.total_bounds\n",
        "\n",
        "# Define the grid cell size in degrees (approximate for 20 meters)\n",
        "# Note: This is a rough approximation and might not be perfectly accurate for all latitudes\n",
        "cell_size_degrees = 20 / 111320  # Roughly 1 degree = 111.32 km, so 20 meters ≈ 20/111320 degrees\n",
        "\n",
        "# Create the grid points\n",
        "xcoords = np.arange(xmin, xmax, cell_size_degrees)\n",
        "ycoords = np.arange(ymin, ymax, cell_size_degrees)\n",
        "\n",
        "# Create a list of grid polygons\n",
        "grid_cells = []\n",
        "for x in xcoords:\n",
        "    for y in ycoords:\n",
        "        polygon = Polygon([(x, y), (x + cell_size_degrees, y),\n",
        "                           (x + cell_size_degrees, y + cell_size_degrees),\n",
        "                           (x, y + cell_size_degrees)])\n",
        "        grid_cells.append(polygon)\n",
        "\n",
        "# Create a GeoDataFrame for the grid\n",
        "grid_gdf = gpd.GeoDataFrame(geometry=grid_cells, crs=bounding_gdf.crs)\n",
        "\n",
        "# Clip the grid to the extent of your bounding GeoDataFrame\n",
        "grid_gdf = gpd.clip(grid_gdf, bounding_gdf.geometry.iloc[0])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "TSLm07qPOtvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creating centroid gdf"
      ],
      "metadata": {
        "id": "x02uqhgfQGoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a GeoDataFrame with the centroids of the grid cells\n",
        "centroid_gdf = selected_polygons_gdf.copy()  # Create a copy to avoid modifying grid_gdf\n",
        "centroid_gdf['geometry'] = centroid_gdf['geometry'].centroid\n",
        "\n",
        "# (Optional) Reset index if needed\n",
        "centroid_gdf = centroid_gdf.reset_index(drop=False) #keep the original index"
      ],
      "metadata": {
        "id": "3Ta8UjahQFsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centroid_gdf.explore()"
      ],
      "metadata": {
        "id": "OyGDv41-lCjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (your existing code to create centroid_gdf and result_gdf) ...\n",
        "\n",
        "# Spatial join to find nearest tree for each centroid\n",
        "# Using 'nearest' predicate to find the closest tree\n",
        "joined_gdf = gpd.sjoin_nearest(centroid_gdf, result_gdf, how='left', distance_col='distance')\n",
        "\n",
        "# Group by centroid index and get the index of the nearest tree\n",
        "nearest_tree_indices = joined_gdf.groupby(joined_gdf.index)['distance'].idxmin()\n",
        "\n",
        "# Create 'remark' column in result_gdf and initialize with 'non mother tree'\n",
        "result_gdf['remark'] = 'non mother tree'\n",
        "\n",
        "# Set 'remark' to 'mother Tree' for the nearest trees\n",
        "result_gdf.loc[nearest_tree_indices, 'remark'] = 'mother Tree'\n",
        "\n",
        "# ... (further processing) ..."
      ],
      "metadata": {
        "id": "og3aWp7vqR6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code needs user input like ('EPSG:32644' or 'EPSG:32645' and so on) This input should use streamlit library. for testing purpose it is being used geopandas library."
      ],
      "metadata": {
        "id": "XNq669DYRsQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'centroid_gdf' and 'result_gdf' are your GeoDataFrames in 'EPSG:4326'\n",
        "\n",
        "# Get user input for projected CRS\n",
        "projected_crs = input(\"Enter the desired projected CRS (e.g., EPSG:32633): \")\n",
        "\n",
        "try:\n",
        "    # Reproject the GeoDataFrames\n",
        "    centroid_gdf_proj = centroid_gdf.to_crs(projected_crs)\n",
        "    result_gdf_proj = result_gdf.to_crs(projected_crs)\n",
        "\n",
        "    # Perform the spatial join in the projected CRS\n",
        "    joined_gdf = gpd.sjoin_nearest(centroid_gdf_proj, result_gdf_proj, how='left', distance_col='distance')\n",
        "\n",
        "    # ... (rest of your code to update 'remark' column) ...\n",
        "\n",
        "except pyproj.exceptions.CRSError as e:\n",
        "    print(f\"Error: Invalid CRS provided. Please enter a valid EPSG code. \\nDetails: {e}\")"
      ],
      "metadata": {
        "id": "KyMKXwwNJevw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Create the interactive map\n",
        "m = result_gdf.explore(column='remark', legend=False)  # Remove default legend\n",
        "\n",
        "# Define a style function to set colors and size based on 'remark'\n",
        "def custom_style_function(feature):\n",
        "    if feature['properties']['remark'] == 'mother Tree':\n",
        "        return {'fillColor': 'red', 'color': 'red', 'radius': 5}  # Red, smaller size\n",
        "    else:\n",
        "        return {'fillColor': 'green', 'color': 'green', 'radius': 1}  # Green, smaller size\n",
        "\n",
        "# Apply the custom style function\n",
        "for _, layer in m._children.items():\n",
        "    if isinstance(layer, folium.features.GeoJson):\n",
        "        layer.style_function = custom_style_function\n",
        "\n",
        "# Calculate the counts of each tree type\n",
        "mother_tree_count = result_gdf[result_gdf['remark'] == 'mother Tree'].shape[0]\n",
        "other_tree_count = result_gdf[result_gdf['remark'] != 'mother Tree'].shape[0]\n",
        "\n",
        "# Create a simple HTML legend using CSS for colored circles and counts\n",
        "legend_html = f\"\"\"\n",
        "<div style=\"position: fixed;\n",
        "            bottom: 50px; left: 50px; width: 150px; height: 120px;\n",
        "            border:1px solid grey; z-index:9999; font-size:15px;\n",
        "            background-color:white; opacity: 0.90; padding: 10px;\">\n",
        "<b>Legend</b><br>\n",
        "<div style=\"display: flex; align-items: center;\">\n",
        "    <div style=\"width: 10px; height: 10px; background-color: red; border-radius: 50%; margin-right: 5px;\"></div> Mother Tree ({mother_tree_count})\n",
        "</div>\n",
        "<div style=\"display: flex; align-items: center;\">\n",
        "    <div style=\"width: 10px; height: 10px; background-color: green; border-radius: 50%; margin-right: 5px;\"></div> Other Trees ({other_tree_count})\n",
        "</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "# Add the legend to the map\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "# Display the map\n",
        "m"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gcGUleeOH3un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#the following code uses geopandas library but it needs to be downloaded using streamlit library. correct the code accordingly."
      ],
      "metadata": {
        "id": "baz6-6njPo1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_gdf.to_csv('result_gdf.csv', index=False)\n",
        "files.download('result_gdf.csv')"
      ],
      "metadata": {
        "id": "2EswFR3E0ORH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `result_gdf` is your GeoDataFrame\n",
        "result_gdf.to_file('result_gdf.kml', driver='KML')\n",
        "\n",
        "# Download the file\n",
        "files.download('result_gdf.kml')"
      ],
      "metadata": {
        "id": "HNcAnE1OBpG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiona"
      ],
      "metadata": {
        "id": "rrlEMGiRIw2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {\n",
        "    'geometry': 'Point',\n",
        "    'properties': OrderedDict([\n",
        "        # ... your desired columns and data types ...\n",
        "        ('TID', 'int'),\n",
        "        ('species', 'str'),\n",
        "        ('LONGITUDE', 'float'),\n",
        "        ('LATITUDE', 'float'),\n",
        "        ('dia_cm', 'float'),\n",
        "        ('height_m', 'float'),\n",
        "        ('class', 'float'),\n",
        "        ('Local_Name', 'str'),\n",
        "        ('stem_volume', 'float'),\n",
        "        ('branch_ratio', 'float'),\n",
        "        ('branch_volume', 'float'),\n",
        "        ('tree_volume', 'float'),\n",
        "        ('cm10diaratio', 'float'),\n",
        "        ('cm10topvolume', 'float'),\n",
        "        ('gross_volume', 'float'),\n",
        "        ('net_volume', 'float'),\n",
        "        ('net_volum_cft', 'float'),\n",
        "        ('firewood_m3', 'float'),\n",
        "        ('firewood_chatta', 'float'),\n",
        "        ('remark', 'str'),\n",
        "\n",
        "\n",
        "        # ... add other columns and their data types ...\n",
        "    ]),\n",
        "}\n",
        "\n",
        "with fiona.open('result_gdf.kml', 'w', driver='KML', crs=result_gdf.crs, schema=schema) as c:\n",
        "    for index, row in result_gdf.iterrows():\n",
        "        c.write({\n",
        "            'geometry': row.geometry.__geo_interface__,\n",
        "            'properties': {\n",
        "                # ... your desired columns and values ...\n",
        "                'TID': row['TID'],\n",
        "                'species': row['species'],\n",
        "                'LONGITUDE': row['LONGITUDE'],\n",
        "                'LATITUDE': row['LATITUDE'],\n",
        "                'dia_cm': row['dia_cm'],\n",
        "                'height_m': row['height_m'],\n",
        "                'class': row['class'],\n",
        "                'Local_Name': row['Local_Name'],\n",
        "                'stem_volume': row['stem_volume'],\n",
        "                'branch_ratio': row['branch_ratio'],\n",
        "                'branch_volume': row['branch_volume'],\n",
        "                'tree_volume': row['tree_volume'],\n",
        "                'cm10diaratio': row['cm10diaratio'],\n",
        "                'cm10topvolume': row['cm10topvolume'],\n",
        "                'gross_volume': row['gross_volume'],\n",
        "                'net_volume': row['net_volume'],\n",
        "                'net_volum_cft': row['net_volum_cft'],\n",
        "                'firewood_m3': row['firewood_m3'],\n",
        "                'firewood_chatta': row['firewood_chatta'],\n",
        "                'remark': row['remark'],\n",
        "\n",
        "                # ... add other columns and their corresponding values ...\n",
        "            }\n",
        "        })\n",
        "\n",
        "files.download('result_gdf.kml')"
      ],
      "metadata": {
        "id": "Mn3f-cm-KVFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}